% This is a sample document using the University of Minnesota, Morris, Computer Science
% Senior Seminar modification of the ACM sig-alternate style. Much of this content is taken
% directly from the ACM sample document illustrating the use of the sig-alternate class. Certain
% parts that we never use have been removed to simplify the example, and a few additional
% components have been added.

% See https://github.com/UMM-CSci/Senior_seminar_templates for more info and to make
% suggestions and corrections.

\documentclass{sig-alternate}
\usepackage{color}

%%%% User-defined macros
\newcommand{\lam}{\lambda}
\newcommand{\mycomment}[1]{\textcolor{red}{#1}}
\newcommand{\vm}[0]{virtual machine}
%%%%% Uncomment the following line and comment out the previous one
%%%%% to remove all comments
%%%%% NOTE: comments still occupy a line even if invisible;
%%%%% Don't write them as a separate paragraph
%\newcommand{\mycomment}[1]{}

\begin{document}

% --- Author Metadata here ---
%%% REMEMBER TO CHANGE THE SEMESTER AND YEAR
\conferenceinfo{UMM CSci Senior Seminar Conference, April 2014}{Morris, MN}

\title{Programming Language Interoperability}

\numberofauthors{1}

\author{
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
\alignauthor
Todd Malone\\
	\affaddr{Division of Science and Mathematics}\\
	\affaddr{University of Minnesota, Morris}\\
	\affaddr{Morris, Minnesota, USA 56267}\\
	\email{malon153@morris.umn.edu}
}

\maketitle
\begin{abstract}
\mycomment{A discussion of systems and methods for the interop of programming languages}
\end{abstract}

\keywords{interoperability, language interoperability, programming language}

\section{Introduction}
Interoperability, colloquially shortened to interop, is the ability for for two or more systems to work together. This definition is very broad, covering anything from groups of people to business or bureaucratic systems to pieces of hardware. Here we will be focusing on the interoperability of programming languages.

In section \ref{Interop} I'll explore why interoperability is desirable, what advantages it can confer, and where it can be useful. This will touch on differing language capabilities, ease of use, hardware independence, and implications for distributed computing.

Next, in sections \ref{VM} and \ref{ML}, I'll describe two particular tools that are used when trying to achieve interoperability, and defining relevant aspects of these settings. These settings will be virtual machines, paying particular attention to the Java Virtual Maching (JVM) and .NET's Common Language Runtime (CLR), and markup languages, with focus on two particular systems that make use of markup languages, Starlink and FML.

Section \ref{approaches} will detail particular challenges to achieving interoperability and approaches to handling them. Following a general description of the approach, I will describe how each tools can be used to implement that approach, along with strengths and weaknesses of each setting.

Section \ref{performance} will explore a few of the performance implications of interoperability.


\section{Interoperability}\label{Interop}
This section will discuss why interoperability is important or desirable.
\begin{itemize}
	\item problem domain: languages have libraries and capabilities build for specific problems. This gives them strength in that area (such as SQL database queries?), but often they have weaknesses in other areas (such as Erlang's strings).
	\item level(?): some languages have finer-grained control over storage (like the C family), while others deal with more abstract and generalize-able data structures (like... java or ruby).
	
	\item Peformance: lower-level languages, like C or Assembly, also byte-codes, have direct access to hardware. This allows some things that more abstract languages, like Java, Ruby, Python, simply cannot do. One of these things is performance. Direct access to hardware allows programmers to make very fined-tuned adjustments that are program or intent specific - too specific for a compiler to reasonably translate them from a more abstract language.
	Additionally, certain programs need hardware access to be useful. \mycomment{I could talk about device drivers like Nic suggested, but are there many others that need both hardware access and abstract structures?}
		
	\item Hardware independance and distributed computing: While interoperability doesn't require these, it can often enable them or result as a side effect of achieving either.
	
	Hardware independence frequently involves writing interpreters for a language that target different hardware systems. In the case of Java, this was done by translating Java into a lower-level language that was easier to write platform-specific runtimes for.
	\mycomment{I need a citation. Additionally, make sure this last bit is actually true}
	Although unintended, this intermediate language provided an opportunity for other languages to interoperate with Java.	
	
	Distributed computing often involves sending data in largely unformatted streams. Because formatting may be needed on the other side, formatting data also must be sent, which can be used by a any language or program that is able to parse the formatting information. I'll take a closer look at this in section \ref{metadata}.
\end{itemize}


\section{Virtual Machines}\label{VM}
The term virtual machine (VM) refers to a process that models the underlying hardware or operating system of a computer, acting as that OS for any programs run on it. In this paper I will be discussing a particular type of virtual machine, known as a process virtual machine. These particular VMs act as runtime environments for a single program, typically written in particular languages, while providing a restricted, managed memory space
\mycomment{I'm not sure if there are other benefits to VMs that are not present in other runtime systems, or if I should mention those anyway.}
.

Virtual machines typically run a language that is low-level and not meant to be human readable, but is above an assembly language. These intermediate languages are therefore still hardware-independant



This section will be a short background on virtual machine environments. This should cover what a virtual machine is (briefly), and the sort of things VM environments add to programming languages. Examples may include JIT compilers, memory management, a common base language...


\section{Markup Languages}\label{ML}
Markup languages are primarily used for describing data. There are a range of languages covering several use cases, from document display or creation to data transfer and storage. For instance, HTML is a markup language used to convey display information about web pages, while TeX is a language used to describe the layout and formatting of text documents. Others include JSON and YAML, which are designed for holding data from programming languages. The two tools we'll be looking at for markup languages will be the Starlink framework and the Fuzzy Markup Language (FML). Both of these use variations of XML, which describes data by enclosing it within tags.

Starlink \cite{Bromberg:2011} is actually more than just a markup language. It is a system \mycomment{(not the right word)} designed to achieve distributed interoperability, built around their own XML-based markup language. This language, the message description language (MDL) is used to model incoming messages from particular protocols.
\mycomment{Note: I'm not sure how detailed I should get about Starlink. There is some interesting stuff they do with automata, but it is complicated and I'm not sure how relevant.}

The Fuzzy Markup Language was not actually designed for interoperating systems at all, but was designed for both hardware and language independence. In effect, this makes it possible to use it in an interoperating system, if one had a distributed system where fuzzy logic would be a useful tool.

\section{Difficulties and Approaches}\label{approaches}
In order to attain interoperability, there are several major things that systems need to account for. Of primary concern is the lowest common denominator (LCD) constraint.
When dealing with multiple languages, a program or system must take into account the weaknesses of the languages involved. While each module of a system can do what it wants internally, when it comes time to pass data around care must be taken that language of the target module actually has a way of representing the data sent to it. \mycomment{some example here}
If it does not, the data specifications must be changed so that both languages can represent the same data at once. This can mean losing type information if a language has no concept of a specific type, or losing flexibility when moving from a weakly typed language to a strongly typed one. It can also mean losing precision of data structures, if a language involved has no way of representing the intricacies of the data structure.

\subsection{Metadata and Data Type Conversion}\label{metadata} \mycomment{\cite{Ide:2010, Bromberg:2011, Hamilton:2003}}
One of the most basic things an interoperating system needs to take into account are the data types involved. 
When passing data between two languages, a system needs to have a way of ensuring that the type restrictions of the LCD are respected. Ide and Pustejovsky \cite{Ide:2010} suggest metadata as the method to accomplish this, and in practice is what both styles use. Metadata is simply data about the data. This can be used to preserve type information when data is passed to a language that has no concept of the data types involved, or establish type information when passing data to a language that requires more strictly defined typing.
\mycomment{Here I can also talk about syntactic/semantic labels/categories via \cite{Ide:2010}. In fact, definitely talk about this. VMs have the advantage of virtually ensuring semantic interoperability because all execution is done through the same language}
\subsubsection*{VMs and metadata}
Virtual machines deal with the concept of metadata in two primary ways. This is mainly handled at compile time by the compiler itself, but this is handled differently depending on the underlying virtual machine.
\begin{itemize}
\item The JVM mainly makes use of Java types. For less strictly-typed languages like Ruby, this means mostly using the Java Object class and using reflection \mycomment{magic} to ensure correct runtime behavior. This is actually a circumvention of the metadata concept, in order to avoid the LCD constraint. In other cases, the metadata is provided by the built-in typing system of Java's byte-code. If bytecode is the lowest common denominator in the system, 
\item CLR: In the CLR, however, language compilers generate metadata about the program along side the compiled program\cite{Hamilton:2003}.
\end{itemize}

\subsubsection*{MLs and metadata}
Markup languages are built with the concept of metadata in mind. A common feature of markup languages is the ability to contain or prepend data with tags, which can effectively act as metadata when used to transfer data between languages.

This is the area where markup languages really shine. Languages like XML can be configured to describe many custom types, and can nest these types to describe components of larger data structures, including descriptions of full objects.

\mycomment{I'm concerned much of the above may need to be transferred to \ref{ML}. I should have enough here to fill the section if I talk about Starlink and FML, but this is something to keep in mind.}

\subsection{Standards and Interfaces}\label{standards}
Metadata is the core of successful interoperability. But if two systems attempting to communicate are expecting differently tagged data, they will still fail to interoperate. Metadata alone is not enough.

One example of this, as demonstrated by Shetty and Vadivel \cite{Shetty:2009}, occurs when trying to process web page output from Java and .NET services. \mycomment{I'm not sure if this is an example I should actually use. Or if I have any examples here}

\subsubsection*{VMs and Standardization}
In a virtual machine system, the standard is frequently already set.\footnote{This is not always the case, but is common practice with recent VMs built with the goal of interop.} Virtual machines come with their intermediate language with its own libraries and type systems. These essentially form the standard: each language hoping to run on a particular virtual machine must be translatable to the intermediate language, which can be used as a sort of lingua franca. Any language built to run on the VM should be able, with little additional effort, be able to interoperate with any other language on that VM.


\subsubsection*{MLs and Standardization}
Standards are not inherent to markup languages, and enforcement cannot be left to underlying hardware or compiler, as they can in a virtual machine setting. Some markup languages have do have standards built for them, such as schema for XML. These provide the same functionality as standards in virtual machines, but must be explicitly enforced by system designers, usually through third-party tools or manual additions to the system.
	
\mycomment{Starlink}



\subsection{Error Handling}\label{errors}

\subsubsection*{VMs and Errors}

\subsubsection*{MLs and errors}


\section{Performance} \label{performance}
Regardless of how the system is built or the interop implemented, an interoperating system will always accrue some overhead. The cost of translating from one language to another can have surprising impacts on efficiency. 

The main issue faced in virtual machines is the LCD constraint. Because all languages eventually end up running in the same language, care must be taken that the intermediate language imposes few constraints on the higher level languages.

Li, White, and Singer show that in the Java Virtual Machine, non-Java languages rely heavily on existing Java code libraries in order to mitigate performance difficulties. Additionally, they found that non-Java languages produced distinctly non-Java sequences of byte-code. While not tested, they indicate that JIT compilation optimization can potentially miss these sequences, as it is tuned to compile byte-code produced by Java.\cite{Li:2013}

The CLR has no similar study, but because it was built to handle multiple languages at once, it is likely able to handle a wider variety of byte-code grammar efficiently. 
\mycomment{Should the previous paragraphs be one?}

The primary concern for markup languages is in translation time. Because systems involving MLs usually also involve different languages at runtime, they also require translating between two or three languages during execution.

Bromberg et al's report on the Starlink framework, which handles three translations per message (two between standard communication protocols and Starlink's internal representation of them, one between internal representations of the two protocols in question), showed a non-negligible time lapse between message and response. The lowest of these was 255 milliseconds, but in a system passing many messages this can add up.

Ultimately, the performance costs of achieving interoperability must be weighed against the potential performance gains. In systems involving several specialized domains, or in systems utilizing diverse hardware, the gains can well out-weigh the costs.



\section{Conclusions}

The two tool sets explored here have widely different applicable systems. 

Virtual machines are much more feasible for systems being built from scratch, where all language decisions are in the hands of the developers. They may also be available to existing programs on a VM which a developer wishes to extend to a larger system; in this case, the extended system merely need be built on the same virtual machine, and it will be able to interoperate with the pre-existing program. More specifically however, virtual machines are most suited to systems that can exist on the same physical machine.

In comparison, markup languages are better suited to dealing with preexisting or legacy systems, where there is too much code to change or parts of the source are simply unavailable \mycomment{Does that happen?},
and so rewriting is not an option. Likewise, if the existing system cannot target a particular virtual machine, perhaps because a compiler from that language to that VM doesn't exist, recompiling the existing program is not feasible.

Additionally, markup languages have an advantage in distributed system environments, where they can be used in sending data over the network. Network nodes have no reason or way to know what language other nodes are running, nor what hardware they are running on. A markup language can act as an intermediary in these cases, describing data in a language-free way.

These two cases are not mutually exclusive, and indeed, markup languages fill a gap that virtual machines simply cannot cover. A real-world system \mycomment{such as kidblog(if allowed)}, will most likely make use of both tools to cover different areas of their system.


%\section{Acknowledgments}


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
% sample_paper.bib is the name of the BibTex file containing the
% bibliography entries. Note that you *don't* include the .bib ending here.
\bibliography{bibliography}  
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

\end{document}
